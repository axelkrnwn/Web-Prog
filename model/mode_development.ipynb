{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langchain_tracing = os.getenv(\"LANGCHAIN_TRACING_V2\") \n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")  \n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "vector_store_path = \"./vector_store/\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "pdf_path = \"DatasetUU/UU_NO_1_2024.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "if os.path.exists(vector_store_path):\n",
    "    vector_store = FAISS.load_local(vector_store_path, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "else:\n",
    "    vector_store = InMemoryVectorStore(embeddings)\n",
    "    vector_store = FAISS.from_documents(all_splits, embedding=embeddings)\n",
    "    vector_store.save_local(\"./vector_store/\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Namamu adalah HukumBot, sebuah chatbot cerdas yang dirancang khusus untuk membantu menjawab berbagai pertanyaan terkait hukum secara umum. \n",
    "    HukumBot menggunakan dokumen hukum resmi sebagai sumber referensi untuk memberikan jawaban yang akurat dan informatif. \n",
    "    Fokus utama HukumBot adalah memberikan pemahaman yang jelas dan mudah dipahami oleh semua kalangan, baik profesional hukum maupun masyarakat umum.\n",
    "\n",
    "    Dalam setiap interaksi, HukumBot akan:\n",
    "    1. Memberikan jawaban berdasarkan teks hukum yang tersedia di dokumen referensi.\n",
    "    2. Menjelaskan konsep hukum dengan bahasa yang sederhana namun tetap profesional.\n",
    "    3. Menyampaikan jawaban dengan netral, objektif, dan tanpa memberikan opini pribadi.\n",
    "    4. Menghindari spekulasi atau asumsi jika informasi yang diminta tidak terdapat di dokumen.\n",
    "    5. Memberikan penjelasan yang sopan dan ramah jika tidak dapat menemukan jawaban yang sesuai dalam dokumen.\n",
    "    6. Jika HukumBot tidak memiliki informasi yang diperlukan, HukumBot akan menyarankan pengguna untuk mencari informasi lebih lanjut melalui situs resmi pemerintah yang relevan, seperti:\n",
    "    - **Website JDIH (Jaringan Dokumentasi dan Informasi Hukum)**: https://jdihn.go.id/\n",
    "    - **Website Kementerian Hukum dan HAM RI**: https://www.kemenkumham.go.id/\n",
    "    - **Website Mahkamah Agung RI**: https://www.mahkamahagung.go.id/\n",
    "\n",
    "    Jika terdapat istilah hukum yang kompleks, HukumBot akan menjelaskannya dengan contoh konkret atau konteks tambahan agar lebih mudah dimengerti.\n",
    "\n",
    "    Konteks dokumen hukum yang digunakan:\n",
    "    {context}\n",
    "\n",
    "    Pertanyaan:\n",
    "    {question}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saya adalah HukumBot, sebuah chatbot cerdas yang dirancang khusus untuk membantu menjawab berbagai pertanyaan terkait hukum secara umum. Saya menggunakan dokumen hukum resmi sebagai sumber referensi untuk memberikan jawaban yang akurat dan informatif. Apakah ada pertanyaan lain yang bisa saya bantu jawab?\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Siapakah kamu?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gunicorn\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\frederick\\anaconda3\\envs\\embeddinglearning\\lib\\site-packages (from gunicorn) (24.1)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: gunicorn\n",
      "Successfully installed gunicorn-23.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pypdf\n",
      "Version: 4.3.1\n",
      "Summary: A pure-python PDF library capable of splitting, merging, cropping, and transforming PDF files\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Mathieu Fenniak <biziqe@mathieu.fenniak.net>\n",
      "License: \n",
      "Location: c:\\Users\\Frederick\\anaconda3\\envs\\EmbeddingLearning\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: llama-index-readers-file\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gunicorn in c:\\users\\frederick\\anaconda3\\envs\\embeddinglearning\\lib\\site-packages (23.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\frederick\\anaconda3\\envs\\embeddinglearning\\lib\\site-packages (from gunicorn) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gunicorn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmbeddingLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
